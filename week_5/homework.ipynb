{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet  -P ./data/raw/yellow/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------+-------------------+----------+-------------------+------+------------------+\n",
      "|ChargingEvent|   CPID| StartDate|          StartTime|   EndDate|            EndTime|Energy|    PluginDuration|\n",
      "+-------------+-------+----------+-------------------+----------+-------------------+------+------------------+\n",
      "|     16673806|AN11719|2017-12-31|2025-03-20 14:46:00|2017-12-31|2025-03-20 18:00:00|   2.4|3.2333333333333334|\n",
      "|     16670986|AN01706|2017-12-31|2025-03-20 11:25:00|2017-12-31|2025-03-20 13:14:00|   6.1|1.8166666666666667|\n",
      "|      3174961|AN18584|2017-12-31|2025-03-20 11:26:11|2018-01-01|2025-03-20 12:54:11|  24.0|25.466666666666665|\n",
      "|     16674334|AN00812|2017-12-31|2025-03-20 15:18:00|2018-01-01|2025-03-20 14:06:00|   6.7|              22.8|\n",
      "|      3176831|AN24139|2017-12-31|2025-03-20 18:25:18|2018-01-01|2025-03-20 13:09:18|   6.1|18.733333333333334|\n",
      "|     16673920|AN03984|2017-12-31|2025-03-20 14:54:00|2017-12-31|2025-03-20 19:19:00|   5.6| 4.416666666666667|\n",
      "|      3174600|AN23243|2017-12-31|2025-03-20 09:43:09|2017-12-31|2025-03-20 11:40:09|   5.0|              1.95|\n",
      "|     16677086|AN01809|2017-12-31|2025-03-20 18:52:00|2018-01-02|2025-03-20 07:19:00|   4.5|             36.45|\n",
      "|      3176550|AN24009|2017-12-31|2025-03-20 16:59:16|2018-01-02|2025-03-20 15:53:16|   5.0|              46.9|\n",
      "|     16678674|AN15542|2017-12-31|2025-03-20 22:47:00|2018-01-01|2025-03-20 12:11:00|  26.1|              13.4|\n",
      "|     16667381|AN05258|2017-12-30|2025-03-20 20:44:00|2017-12-31|2025-03-20 12:31:00|  18.5|15.783333333333333|\n",
      "|     16656684|AN03155|2017-12-30|2025-03-20 00:08:00|2017-12-30|2025-03-20 11:08:00|  23.7|              11.0|\n",
      "|     16665909|AN15633|2017-12-30|2025-03-20 22:08:00|2017-12-31|2025-03-20 07:34:00|   8.6| 9.433333333333334|\n",
      "|     16656833|AN16585|2017-12-30|2025-03-20 11:06:00|2017-12-30|2025-03-20 11:21:00|   1.6|              0.25|\n",
      "|      3170740|AN18094|2017-12-30|2025-03-20 11:49:11|2017-12-31|2025-03-20 12:26:11|  15.0|24.616666666666667|\n",
      "|     16659519|AN08473|2017-12-30|2025-03-20 14:24:00|2017-12-30|2025-03-20 16:12:00|   1.8|               1.8|\n",
      "|     16664521|AN16361|2017-12-30|2025-03-20 19:35:00|2017-12-31|2025-03-20 14:32:00|   3.5|             18.95|\n",
      "|     16662170|AN11067|2017-12-30|2025-03-20 17:07:00|2017-12-31|2025-03-20 08:15:00|   6.5|15.133333333333333|\n",
      "|     16661855|AN12077|2017-12-30|2025-03-20 16:50:00|2017-12-30|2025-03-20 18:56:00|   6.5|               2.1|\n",
      "|     16666777|AN08012|2017-12-30|2025-03-20 11:00:00|2017-12-31|2025-03-20 08:34:00|   3.1|21.566666666666666|\n",
      "+-------------+-------+----------+-------------------+----------+-------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    DecimalType,\n",
    "    DoubleType,\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"ChargingEvent\", StringType(), True),\n",
    "        StructField(\"CPID\", StringType(), True),\n",
    "        StructField(\"StartDate\", StringType(), True),\n",
    "        StructField(\"StartTime\", StringType(), True),\n",
    "        StructField(\"EndDate\", StringType(), True),\n",
    "        StructField(\"EndTime\", StringType(), True),\n",
    "        StructField(\"Energy\", DecimalType(scale=1), True),\n",
    "        StructField(\"PluginDuration\", DoubleType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# df = spark.read.option(\"header\", True).schema(schema).csv(\"./electric-chargepoints-2017.csv\")\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", \"true\").csv(\"./electric-chargepoints-2017.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ChargingEvent: integer (nullable = true)\n",
      " |-- CPID: string (nullable = true)\n",
      " |-- StartDate: date (nullable = true)\n",
      " |-- StartTime: timestamp (nullable = true)\n",
      " |-- EndDate: date (nullable = true)\n",
      " |-- EndTime: timestamp (nullable = true)\n",
      " |-- Energy: double (nullable = true)\n",
      " |-- PluginDuration: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read \\\n",
    "    .parquet('./data/raw/yellow/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_yellow = spark.read \\\n",
    "    .parquet('./data/raw/yellow/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "df_yellow = df_yellow.repartition(4)\n",
    "df_yellow.write.parquet(\"./data/parquet/yellow/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh ./data/parquet/yellow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "(\n",
    "    df_yellow.filter(\n",
    "        F.to_date(F.col(\"tpep_pickup_datetime\")) == \"2024-10-15\")\n",
    "    # .orderBy(\"tpep_pickup_datetime\", ascending=False)\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 - pandas\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_pd = pd.read_parquet(\"./data/parquet/yellow/\")\n",
    "df_pd[\"pickup_date\"] = df_pd[\"tpep_pickup_datetime\"].dt.date\n",
    "df_pd[df_pd[\"pickup_date\"] == datetime.strptime(\"2024-10-15\", \"%Y-%m-%d\").date()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd[\"tpep_pickup_str\"] = df_pd[\"tpep_pickup_datetime\"].astype(str).str.split(\" \").str[0]\n",
    "df_pd[\"pickup_str\"] = df_pd[\"pickup_date\"].astype(str)\n",
    "df_pd[df_pd[\"tpep_pickup_str\"] != df_pd[\"pickup_str\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "(\n",
    "    df_yellow\n",
    "        .withColumn(\"trip_duration\", \n",
    "                    (F.to_timestamp(F.col(\"tpep_dropoff_datetime\")).cast(\"long\") \n",
    "                     - F.to_timestamp(F.col(\"tpep_pickup_datetime\")).cast(\"long\")) / 3600\n",
    "                )\n",
    "        .select(\"tpep_dropoff_datetime\", \"tpep_pickup_datetime\", \"trip_duration\")\n",
    "        .orderBy(\"trip_duration\", ascending=False)\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max((pd.to_datetime(df_pd[\"tpep_dropoff_datetime\"])\n",
    " - pd.to_datetime(df_pd[\"tpep_pickup_datetime\"])) / np.timedelta64(1, 'h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv  -P ./data/raw/lookup/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(\"./data/raw/lookup/taxi_zone_lookup.csv\")\n",
    "\n",
    "df_lookup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_yellow\n",
    "    .join(df_lookup, df_yellow.PULocationID == df_lookup.LocationID, \"inner\")\n",
    "    .groupBy(\"Zone\").count()\n",
    "    .orderBy(\"count\")\n",
    ").head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
